{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fitz\n",
    "\n",
    "import pyodbc\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "path2add = os.path.normpath(os.path.abspath(\n",
    "    os.path.join(os.path.dirname(__file__), os.path.pardir)))\n",
    "if (not (path2add in sys.path)):\n",
    "    sys.path.append(path2add)\n",
    "from py_elisa_reader import check_no_dup_get_position_big, check_no_dup_get_position_ipv, check_no_dup_get_position_small, fetch_values_big_table, fetch_values_ipv_table, fetch_values_small_table, fetch_values_small_table_big_font, insert_sql  # NOQA\n",
    "\n",
    "pdf_path = r\"Neubukow4_DE13-015_Sonder IBD.pdf\"\n",
    "\n",
    "doc = fitz.open(pdf_path)\n",
    "db_path = r\"C:/Synch/MMT.mdb\"\n",
    "\n",
    "connection_str = (\n",
    "    rf\"DRIVER={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={db_path}\"\n",
    ")\n",
    "connection = pyodbc.connect(connection_str)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "TABLE_NAME = 'LaborbefundT'\n",
    "COLUMNS_BIG = 'BelegKomplett, PositionLab, ErgebnissDatum, Labornummer, Material, Kennzeichnung, Methode, Krankheit, Probenanzahl, AnzahlPos, AnzahlNeg, na, Titer, cv'\n",
    "COLUMNS_SMALL = 'BelegKomplett, PositionLab, ErgebnissDatum, Material, Kennzeichnung, Methode, Krankheit, Probenanzahl, AnzahlPos, AnzahlNeg, na'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def correct_next_page_postions(next_page: list, page_before: list) -> list:\n",
    "    # We need to adjust page positions for multiple page reports, as positions of blocks are used on following pages\n",
    "    page_before_last_index = page_before[-1][-2]\n",
    "    new_start_index = page_before_last_index + 1\n",
    "    for i in range(len(next_page)):\n",
    "        next_page[i] = list(next_page[i])\n",
    "        next_page[i][-2] += new_start_index\n",
    "\n",
    "    return next_page\n",
    "\n",
    "\n",
    "\n",
    "# Pages that are processed as next pages and therefore skipped in the main loop\n",
    "skip_page_indices = []\n",
    "\n",
    "pages = list(doc.pages())\n",
    "\n",
    "for i in range(len(pages)):\n",
    "\n",
    "    if i in skip_page_indices:\n",
    "        continue\n",
    "    try:\n",
    "        content_list = pages[i].get_text(\"blocks\")\n",
    "        big_table = False\n",
    "        small_table = False\n",
    "        small_table_big_font = False\n",
    "        small_ipv_table = False\n",
    "\n",
    "        for block in content_list:\n",
    "            # Check which kind of page (big table, small table, not parseable)\n",
    "            if block[5] == 7 and \"Firma\" in block[4]:  # def is_big_table\n",
    "                big_table = True\n",
    "                break\n",
    "            if \"Titergruppen\" in block[4]:\n",
    "                small_ipv_table = True\n",
    "                break\n",
    "            if block[5] == 13 and \"Test\" in block[4]:\n",
    "                small_table = True\n",
    "                for block in content_list:\n",
    "                    if \"Titergruppen\" in block[4]:\n",
    "                        small_table = False\n",
    "                        small_ipv_table = True\n",
    "                        break\n",
    "                break\n",
    "            if block[5] == 5 and \"Test\" in block[4]:\n",
    "                small_table_big_font = True\n",
    "                break\n",
    "\n",
    "        # Determine whether it is a multi-page report:\n",
    "        might_have_next_page = True\n",
    "        potential_next_page_index = i + 1\n",
    "        page_before_content = content_list\n",
    "        while might_have_next_page:\n",
    "            if potential_next_page_index >= len(pages):\n",
    "                break\n",
    "            # TODO: Implement logice for small_table_big_font and small_ipv_table\n",
    "            next_page_content = pages[potential_next_page_index].get_text(\n",
    "                \"blocks\")\n",
    "            is_next_page_condition = False\n",
    "\n",
    "            if small_table:\n",
    "                # Das ist mal wieder ein Vorschlaghammerapproach hier...\n",
    "                if len(next_page_content) >= 4:\n",
    "                    is_next_page_condition = \"Vertiefung\" in next_page_content[3][4]\n",
    "                else:\n",
    "                    might_have_next_page = False\n",
    "            # Not necessary - mutliple pages are counted differently..\n",
    "            if big_table:\n",
    "                # using position number would be prettier...\n",
    "                if next_page_content:\n",
    "                    is_next_page_condition = \"pos\" in next_page_content[0][\n",
    "                        4] or \"neg\" in next_page_content[0][4] or \"sus\" in next_page_content[0][4]\n",
    "            # TODO: Add:\n",
    "            #  if small_table_big font:\n",
    "            # ...\n",
    "            # if small_ipv_table:\n",
    "            # ...\n",
    "\n",
    "            if is_next_page_condition:\n",
    "                next_page_content = correct_next_page_postions(\n",
    "                    # We have to adjust position indices to avoid problems down the road.\n",
    "                    next_page_content, page_before_content)\n",
    "                page_before_content = next_page_content\n",
    "                content_list = content_list + next_page_content\n",
    "                skip_page_indices.append(potential_next_page_index)\n",
    "                potential_next_page_index += 1\n",
    "\n",
    "            else:\n",
    "                might_have_next_page = False\n",
    "\n",
    "        if big_table:  # Assign the function\n",
    "            values = fetch_values_big_table(content_list)\n",
    "            no_dup_and_position = check_no_dup_get_position_big(values)\n",
    "            if no_dup_and_position[0]:\n",
    "                position_lab = no_dup_and_position[1]\n",
    "                params = list(values)\n",
    "                params.insert(1, position_lab)\n",
    "                insert_sql(cursor, TABLE_NAME, COLUMNS_BIG, params)\n",
    "            else:\n",
    "                print(\"Entry already exists, Skipping ...\")\n",
    "        elif small_table:\n",
    "            values = fetch_values_small_table(content_list)\n",
    "            no_dup_and_position = check_no_dup_get_position_small(values)\n",
    "            if no_dup_and_position[0]:\n",
    "                position_lab = no_dup_and_position[1]\n",
    "                params = list(values)\n",
    "                params.insert(1, position_lab)\n",
    "                insert_sql(cursor, TABLE_NAME, COLUMNS_SMALL, params)\n",
    "            else:\n",
    "                print(\"Entry already exists, Skipping ...\")\n",
    "        elif small_ipv_table:\n",
    "            values = fetch_values_ipv_table(content_list)\n",
    "            no_dup_and_position = check_no_dup_get_position_ipv(values)\n",
    "            if no_dup_and_position[0]:\n",
    "                position_lab = no_dup_and_position[1]\n",
    "                params = list(values)\n",
    "                params.insert(1, position_lab)\n",
    "                insert_sql(cursor, TABLE_NAME, COLUMNS_BIG, params)\n",
    "            else:\n",
    "                print(\"Entry already exists, Skipping ...\")\n",
    "\n",
    "        elif small_table_big_font:\n",
    "            values = fetch_values_small_table_big_font(content_list)\n",
    "            no_dup_and_position = check_no_dup_get_position_small(values)\n",
    "            if no_dup_and_position[0]:\n",
    "                position_lab = no_dup_and_position[1]\n",
    "                params = list(values)\n",
    "                params.insert(1, position_lab)\n",
    "                insert_sql(cursor, TABLE_NAME, COLUMNS_SMALL, params)\n",
    "            else:\n",
    "                print(\"Entry already exists, Skipping ...\")\n",
    "        else:\n",
    "            print(\"Could not parse page.\")\n",
    "            values = None\n",
    "            continue\n",
    "\n",
    "        print(values)\n",
    "    except UnboundLocalError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "While might_have_next_page:\n",
    " if next page:\n",
    "    FU pageType\n",
    "        if next page has ordinal in key Position:\n",
    "            content_list append page content\n",
    "        else:\n",
    "            might_have_next_page = False\n",
    " else:\n",
    "  might_have_next_page = False\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py32",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
